{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of merging precipitation data with the PFAS file. The precipitation data is for Orange County, 2010-2019 and was accessed from the NOAA Climate Data Online Search (https://www.ncdc.noaa.gov/cdo-web/search?datasetid=GHCND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "def deg2rad(deg):\n",
    "    return(deg*(math.pi/180.))\n",
    "def getDistanceFromLatLonInKm(lat1,lon1,lat2,lon2):\n",
    "    R=6371.\n",
    "    dlat=deg2rad(lat2-lat1)\n",
    "    dlon=deg2rad(lon2-lon1)\n",
    "    a=math.sin(dlat/2.)*math.sin(dlat/2.) + math.cos(deg2rad(lat1)) *\\\n",
    "    math.cos(deg2rad(lat2)) *math.sin(dlon/2.)*math.sin(dlon/2.)\n",
    "\n",
    "    b = 2. * math.atan2(math.sqrt(a),math.sqrt(1-a))\n",
    "    d=R*b\n",
    "    return(d)\n",
    "\n",
    "prec=pd.read_csv(\"precip_2010_2019.csv\")[['STATION','LATITUDE','LONGITUDE','ELEVATION','DATE','PRCP','TAVG','TMAX','TMIN']]\n",
    "prec['DATE']=pd.to_datetime(prec['DATE'])\n",
    "dat=pd.read_excel(\"SAR-Imperial_537Data_AsOf08-08-2019.xlsx\",sheet_name='All')\n",
    "location_data=pd.read_excel(\"SAR-Imperial_537Data_AsOf08-08-2019.xlsx\",sheet_name='SAR-IMPERIAL-01 Location')\n",
    "dat['latitude']=float(location_data['Latitude_WGS84'])\n",
    "dat['longitude']=float(location_data['Longitude_WGS84'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to take precipitation data and match it with the location of the PFAS data\n",
    "def match_prec_pfas(prec_table,pfas_table,\n",
    "                    prec_stat_name='STATION',pfas_stat_name='Station Name',\n",
    "                   prec_lat_name='LATITUDE',prec_lon_name='LONGITUDE',\n",
    "                   pfas_lat_name='latitude',pfas_lon_name='longitude'):\n",
    "    #Find the closest precip station to the PFAS station\n",
    "    prec_stations=prec_table[[prec_stat_name,prec_lat_name,prec_lon_name]].drop_duplicates()\n",
    "    pfas_stations=pfas_table[[pfas_stat_name,pfas_lat_name,pfas_lon_name]].drop_duplicates()\n",
    "    #Make table of distances\n",
    "    comb_dist=pd.DataFrame()\n",
    "    for s in pfas_stations[pfas_stat_name]:\n",
    "        #Get the lat/lon coords for the station\n",
    "        pfas_sub=pfas_stations[pfas_stations[pfas_stat_name]==s]\n",
    "        pfas_lat=float(pfas_sub[pfas_lat_name])\n",
    "        pfas_lon=float(pfas_sub[pfas_lon_name])\n",
    "        for p in prec_stations[prec_stat_name]:\n",
    "            prec_sub=prec_stations[prec_stations[prec_stat_name]==p]\n",
    "            prec_lat=float(prec_sub[prec_lat_name])\n",
    "            prec_lon=float(prec_sub[prec_lon_name])\n",
    "            dict_store={}\n",
    "            dict_store['pfas_s']=s\n",
    "            dict_store['prec_s']=p\n",
    "            dict_store['dist_betw']=getDistanceFromLatLonInKm(pfas_lat,pfas_lon,prec_lat,prec_lon)\n",
    "            comb_dist=comb_dist.append(dict_store,ignore_index=True)\n",
    "    #Find the min distance\n",
    "    stat_match=pd.DataFrame(columns=['pfas_s','prec_s','dist_betw'])\n",
    "    for s in pfas_stations[pfas_stat_name]:\n",
    "        comb_sub=comb_dist[comb_dist['pfas_s']==s]\n",
    "        min_dist=comb_sub.loc[comb_sub['dist_betw'].idxmin()]\n",
    "        stat_match=stat_match.append(min_dist)\n",
    "    return(stat_match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dist=match_prec_pfas(prec,dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_prec_pfas_df(prec_table,pfas_table,match_table,left_mergename,right_mergename,\n",
    "                      prec_station_name='STATION',pfas_station_name='Station Name'):\n",
    "    merged_table=pd.DataFrame()\n",
    "    for w in pfas_table[pfas_station_name].unique():\n",
    "        pfas_sub=pfas_table[pfas_table[pfas_station_name].str.match(w)]\n",
    "        match_sub=match_table[match_table['pfas_s'].str.match(w)]\n",
    "        prec_sub=prec_table[prec_table[prec_station_name].str.match(match_sub['prec_s'].item())]\n",
    "        merged_dat=pd.merge(pfas_sub,prec_sub,left_on=left_mergename,right_on=right_mergename)\n",
    "        merged_table=merged_table.append(merged_dat)\n",
    "    return(merged_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Merge the data by the date?\n",
    "prec_tomerge=prec[prec['STATION'].str.match(min_dist['prec_s'].item())]\n",
    "dat_merged=pd.merge(prec_tomerge,dat,left_on='DATE',right_on='Sample Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_sort=dat_merged.sort_values(by=['DATE'])\n",
    "dat_sort.to_csv('SAR-Imperial_merged_precip.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another dataset\n",
    "new_dat=pd.read_csv('gama_pf_orange.csv')\n",
    "new_dat['DATE']=pd.to_datetime(new_dat['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_match=match_prec_pfas(prec,new_dat,pfas_stat_name='WELL ID',pfas_lat_name='APPROXIMATE LATITUDE',pfas_lon_name='APPROXIMATE LONGITUDE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oc_merged=merge_prec_pfas_df(prec,new_dat,dat_match,'DATE','DATE',pfas_station_name='WELL ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "oc_merged=pd.DataFrame()\n",
    "for w in new_dat['WELL ID'].unique():\n",
    "    dat_sub=new_dat[new_dat['WELL ID']==w]\n",
    "    match_sub=dat_match[dat_match['pfas_s']==w]\n",
    "    prec_sub=prec[prec['STATION'].str.match(match_sub['prec_s'].item())]\n",
    "    merged_dat=pd.merge(dat_sub,prec_sub,left_on='DATE',right_on='DATE')\n",
    "    oc_merged=oc_merged.append(merged_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "oc_merged.to_csv('oc_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
